# -*- coding: utf-8 -*-
"""Project_SebastianKrzosek.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EZ3yCxdpevDTKSBUn1nGZ7CgNUoOD9k_
"""

import numpy as np
import pandas as pd
import seaborn as sns
import statsmodels.api as sm
import matplotlib.pyplot as plt
from scipy import stats
from scipy.stats import shapiro
from sklearn.cluster import KMeans
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import MinMaxScaler
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from statsmodels.stats.stattools import durbin_watson

from google.colab import files #Wrzucenie pliku csv do colaba
uploaded = files.upload()      # otwierajac normalnie plik .py nie trzeba wywolywac

wine = pd.read_csv("./winequality-red.csv" , sep=";" ) #wczytanie bazy win czerwonych
wine

#Sprawdzając poprawność danych, nie zauważyłem żadnych braków bądź niepoprawności. Jedyną rzeczą na która zwróciłem uwagę, 
#były rozwinięcia okresowe w alcoholu. Postanowiłem zaokrąglić je do 4 miejsc po przecinku.
wine['alcohol'] = round(wine["alcohol"], 4)

#Wybór predyktorów
x = wine[["fixed acidity","volatile acidity","citric acid","residual sugar","chlorides","free sulfur dioxide","total sulfur dioxide","density","pH","sulphates","alcohol"]]
#oraz zmiennej celu
y = wine[['quality']]

#Podział danych na zbiór uczący oraz testowy 70/30 z indeksem jako ziarno generatora liczb pseudolosowych
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=300136, stratify=y)

#Stworzenie macierzy korelacji w celu zbadania powiazań miedzy zmiennymi
cols = ["fixed acidity","volatile acidity","citric acid","residual sugar","chlorides","free sulfur dioxide","total sulfur dioxide","density","pH","sulphates","alcohol"]
cm = np.corrcoef(x_train[cols].values.T)
hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 8}, yticklabels=cols, xticklabels=cols)
plt.show()
#mozemy zauwazyć, że zmienne nie są ze soba skorelowane, dlatego też jako predyktorów w modelu użyjemy wszyskich.
#na tym etapie wydaje mi się, że wszystkie zmienne wpływają w podobnym stopniu na jakość wina. Żadna z nich nie wyróżnia się
#natomiast po zaczerpnieciu informacji z internetu, wiem że do klasyfikacji win na wytrawne, półwytrawne, półsłodkie i słodkie
#znaczenie będą miały zmienne takie jak zawartość alkoholu, cukier, kwasowosc ogólna (PH), kwasowość lotna

###########################################
#                   KNN                   #
###########################################

#Problem klasyfikacji postanowiłem rozwiązać algorytmem KNN
#Dokonujemy standaryzacji naszych predyktorow
x_train_stand = stats.zscore(x_train)
x_test_stand = stats.zscore(x_test)

#a nastepnie uruchamiamy algorytm KNN dla: k=4 używając metryki euklidesowej.
knn = KNeighborsClassifier(4, weights='uniform', metric='euclidean')
knn.fit(x_train_stand, y_train["quality"])
y_predict=knn.predict(x_test_stand)

set(wine["quality"])
#Mozemy tutaj zauwazyć, że nasze wina przyjmują jedynie oceny jakości z przedziału 3-8 (nie 1-10)

#Tworzymy macierz pomyłek
conf_matrix=confusion_matrix(y_test,y_predict)
summ = 0
fullSumm = 0
for i in range(6):
    for j in  range(6):
        if(i == j):
            summ += conf_matrix[i][j]
        fullSumm += conf_matrix[i][j]

print(conf_matrix)
print()
print("Trafność: " + str(summ) + "/" +str(fullSumm)+ " = " + str(summ/fullSumm))

#Tworzymy macierz pomyłek z odstepstwem o jeden
summ = 0
fullSumm = 0
for i in range(6):
    for j in  range(6):
        if(i == j or (i-1 == j and i > 0) or (i+1 == j and j < 6)):
            summ += conf_matrix[i][j]
        fullSumm += conf_matrix[i][j]

print(conf_matrix)
print()
print("Trafność z odstepstwem o 1: " + str(summ) + "/" +str(fullSumm)+ " = " + str(summ/fullSumm))

print('MAE: ',mean_absolute_error(y_test, y_predict))

###########################################
#                   MLP                   #
###########################################

#Problem szacowania postanowilem rozwiazac poprzez MLP
#Standaryzacja Min-Max dla MLP
scaler = MinMaxScaler()
scaler.fit(x_train)
x_train_stand_mlp = scaler.transform(x_train)
x_test_stand_mlp = scaler.transform(x_test)

scaler2 = MinMaxScaler()
scaler2.fit(pd.DataFrame(y_train))
y_train_stand_mlp = scaler2.transform(pd.DataFrame(y_train))
y_test_stand_mlp = scaler2.transform(pd.DataFrame(y_test))

#Budowa sieci 
siec_neur = MLPRegressor(hidden_layer_sizes=(8,), activation='tanh',solver='lbfgs', alpha=0.0001, max_iter=10000, random_state=300136)
#Uczenie jej
siec_train=siec_neur.fit(x_train_stand_mlp, y_train_stand_mlp.ravel())
#Przewidywanie wartości 
y_predict_mlp = siec_neur.predict(x_test_stand_mlp)

#Dokonujemy denormalizacji zmiennych
y_predict_denorm = np.zeros(y_predict_mlp.shape[0]) 
maximum = max(pd.DataFrame(y_test)["quality"])
minimum = min(pd.DataFrame(y_test)["quality"])

i=0
while i<= (y_predict_mlp.shape[0]-1):
      y_predict_denorm[i] = (y_predict_mlp[i]*(maximum-minimum)) + minimum
      i+=1

y_predict_denorm_round = np.round(y_predict_denorm)

conf_matrix_mlp = confusion_matrix(y_test, y_predict_denorm_round)
summ = 0
fullSumm = 0
for i in range(6):
    for j in  range(6):
        if(i == j):
            summ += conf_matrix_mlp[i][j]
        fullSumm += conf_matrix_mlp[i][j]

print(conf_matrix_mlp)
print()
print("Trafność : " + str(summ) + "/" +str(fullSumm)+ " = " + str(summ/fullSumm))

summ = 0
fullSumm = 0
for i in range(6):
    for j in  range(6):
        if(i == j or (i-1 == j and i > 0) or (i+1 == j and j < 6)):
            summ += conf_matrix_mlp[i][j]
        fullSumm += conf_matrix_mlp[i][j]

print(conf_matrix_mlp)
print()
print("Trafność z odstepstwem o 1: " + str(summ) + "/" +str(fullSumm)+ " = " + str(summ/fullSumm))

print('MAE: ',mean_absolute_error(y_test, y_predict_denorm_round))

###########################################
#           Algorytm Centroidów           #
#               K-Średnich                #
###########################################

#ax = sns.boxplot(data=wine['fixed acidity']) #wykres skrzynkowy
wine['fixed acidity'].plot(kind='hist', title='Histogram of fixed acidity') #histogram
#histogram prawostronnie skosny, delikatnie przypomina rozkład normalny.

wine['volatile acidity'].plot(kind='hist', title='Histogram of volatile acidity') 
#histogram niesymetryczny

wine['citric acid'].plot(kind='hist', title='Histogram of citric acid') 
#histogram niesymetryczny

wine['residual sugar'].plot(kind='hist', title='residual sugar') 
#histogram mocno prawostronnie skośny

wine['chlorides'].plot(kind='hist', title='Histogram of chlorides') 
#histogram mocno prawostronnie skośny

wine['free sulfur dioxide'].plot(kind='hist', title='Histogram of free sulfur dioxide') 
#histogram niesymetryczny - prawostronnie skośny

wine['total sulfur dioxide'].plot(kind='hist', title='Histogram of total sulfur dioxide') 
#histogram niesymetryczny - prawostronnie skośny

wine['density'].plot(kind='hist', title='Histogram of density') 
#histogram symetryczny, rozklad zblizony do normalnego

wine['pH'].plot(kind='hist', title='Histogram of pH') 
#histogram symetryczny, na pierwszy rzut oka wyglada idealnie - rozklad zblizony do normalnego

wine['sulphates'].plot(kind='hist', title='Histogram of sulphates') 
#histogram niesymetryczny - prawostronnie skośny

wine['alcohol'].plot(kind='hist', title='Histogram of alcohol') 
#histogram niesymetryczny - prawostronnie skośny

#operacje na zmiennych 
wine_k_means = wine.copy()
wine_k_means[cols]=stats.zscore(np.log(wine_k_means[cols]+1))  # ln(x) + 1

wine_k_means['fixed acidity'].plot(kind='hist', title='Histogram of fixed acidity') 
#histogram wciąż prawostronnie skosny, bardziej niż poprzedni przypomina rozkład normalny.

wine_k_means['volatile acidity'].plot(kind='hist', title='Histogram of volatile acidity')
#histogram wciaz niesymetryczny, aczkolwiek mniej

wine_k_means['citric acid'].plot(kind='hist', title='Histogram of citric acid')
#histogram wciaz niesymetryczny, aczkolwiek mniej - widac poprawe

wine_k_means['residual sugar'].plot(kind='hist', title='residual sugar') 
#histogram wciąż mocno prawostronnie skośny

wine_k_means['chlorides'].plot(kind='hist', title='chlorides') 
#histogram sie poprawil, aczkolwiek delikatnie prawostronnie skosny

wine_k_means['free sulfur dioxide'].plot(kind='hist', title='Histogram of free sulfur dioxide') 
#poprawa

wine_k_means['total sulfur dioxide'].plot(kind='hist', title='Histogram of total sulfur dioxide') 
#piekna poprawa - histogram niemalże idealny

wine_k_means['density'].plot(kind='hist', title='Histogram of density')
#Ladny histogram zblizony do rozkladu normalnego

wine_k_means['pH'].plot(kind='hist', title='Histogram of pH')
#Histogram zblizony do rozkladu normalnego

wine_k_means['sulphates'].plot(kind='hist', title='Histogram of sulphates')
#Wyraźna poprawa, delikatnie prawostronnie skośny

wine_k_means['alcohol'].plot(kind='hist', title='Histogram of alcohol')
#poprawa - wciaz nie przypomina rozkladu normalnego (prawostronnie skośny)

#Algorytm K-Średnich dla 3 klastrów z moim indeksem jako ziarno generatora liczb pseudolosowych (przy podziale na 4 klastry jeden jest bardzo nieliczny)
km = KMeans(n_clusters=3, init='random', n_init=10, max_iter=300, tol=1e-04, random_state=300136)

kmeans=km.fit(wine_k_means[cols])
cluster=kmeans.labels_
Cluster0 = wine_k_means[cols].loc[cluster == 0]
Cluster1 = wine_k_means[cols].loc[cluster == 1]
Cluster2 = wine_k_means[cols].loc[cluster == 2]

opis1 = Cluster0.describe()
opis2 = Cluster1.describe()
opis3 = Cluster2.describe()

opis1
#Wina wytrawne ze wzgledu na najniższa zawartość tlenków siarki, siarczanów i cukru.
#bardzo liczny - 576 obserwacji
#stała kwasowość poniżej sredniej
#lotna kwasowość powyżej sredniej
#kwas cytrynowy poniżej sredniej
#cukier resztkowy  poniżej sredniej
#chlorki ponizej sredniej
#wolny dwutlenek siarki poniżej sredniej
#całkowity dwutlenek siarki poniżej sredniej
#gęstość poniżej sredniej
#pH powyżej sredniej
#siarczany poniżej sredniej
#alkohol powyżej sredniej

opis2
#PółSlodkie ze wzgledu na wysoka ilosc siarczanu i srednia zawartość cukru.
#rownież liczny zbiór 476 obserwacji
#stała kwasowość  powazej sredniej
#lotna kwasowość poniżej średniej
#kwas cytrynowy powyżej sredniej
#cukier resztkowy poniżej sredniej
#chlorki ponizej poniżej sredniej
#wolny dwutlenek siarki poniżej sredniej
#całkowity dwutlenek siarki poniżej sredniej
#gęstość delikatnie powyżej sredniej
#pH zdecydowanie poniżej sredniej
#siarczany delikatnie powyżej sredniej
#alkohol delikatnie powyżej sredniej

opis3 
# Są to wina prawdopodobnie słodkie ze wzgledu na wiekszą zawartość tlenków siarki i delikatnie powyższą zawartość cukrów
# liczny zbiór - 547 obserwacji
#stała kwasowość  poniżej sredniej
#lotna kwasowość delikatnie powyżej średniej
#kwas cytrynowy delikatnie powyżej sredniej
#cukier resztkowy powyżej sredniej
#chlorki ponizej delikatnie poniżej sredniej
#wolny dwutlenek siarki powyżej sredniej
#całkowity dwutlenek siarki powyżej sredniej
#gęstość powyżej sredniej
#pH delikatnie poniżej sredniej
#siarczany lekko poniżej sredniej
#alkohol poniżej sredniej

#Rysujemy histogramy dla klastrow. Klaster 0.
#Wybieramy te obserwacje zmiennej quality, ktore sa zwiazane z klastrem 0
wine_0=wine['quality'][cluster==0]
# Separujemy wartosci zmiennej quality ze wzgledu na ocene <3-8>
wine_0_3=wine_0[wine_0==3]
wine_0_4=wine_0[wine_0==4]
wine_0_5=wine_0[wine_0==5]
wine_0_6=wine_0[wine_0==6]
wine_0_7=wine_0[wine_0==7]
wine_0_8=wine_0[wine_0==8]

#Rysujemy histogramy dla klastrow. Klaster 1.
#Wybieramy te obserwacje zmiennej quality, ktore sa zwiazane z klastrem 1.
wine_1=wine['quality'][cluster==1]
# Separujemy wartosci zmiennej quality ze wzgledu na ocene <3-8>
wine_1_3=wine_1[wine_1==3]
wine_1_4=wine_1[wine_1==4]
wine_1_5=wine_1[wine_1==5]
wine_1_6=wine_1[wine_1==6]
wine_1_7=wine_1[wine_1==7]
wine_1_8=wine_1[wine_1==8]

#Rysujemy histogramy dla klastrow. Klaster 2.
#Wybieramy te obserwacje zmiennej quality, ktore sa zwiazane z klastrem 2.
wine_2=wine['quality'][cluster==2]
# Separujemy wartosci zmiennej quality ze wzgledu na ocene <3-8>
wine_2_3=wine_2[wine_2==3]
wine_2_4=wine_2[wine_2==4]
wine_2_5=wine_2[wine_2==5]
wine_2_6=wine_2[wine_2==6]
wine_2_7=wine_2[wine_2==7]
wine_2_8=wine_2[wine_2==8]

#Rysujemy histogramy dla klastrow. Klaster 3.
#Wybieramy te obserwacje zmiennej quality, ktore sa zwiazane z klastrem 3.
wine_3=wine['quality'][cluster==3]
# Separujemy wartosci zmiennej quality ze wzgledu na ocene <3-8>
wine_3_3=wine_3[wine_3==3]
wine_3_4=wine_3[wine_3==4]
wine_3_5=wine_3[wine_3==5]
wine_3_6=wine_3[wine_3==6]
wine_3_7=wine_3[wine_3==7]
wine_3_8=wine_3[wine_3==8]

plt.hist([wine_0_3,wine_0_4,wine_0_5,wine_0_6,wine_0_7,wine_0_8], bins=6, stacked=True, color=['green', 'red', "yellow", "blue", "pink", "orange"], label = ['Quality=3', 'Quality=4','Quality=5','Quality=6','Quality=3','Quality=8' ])
handles, labels = plt.gca().get_legend_handles_labels()
plt.legend(reversed(handles), reversed(labels))
plt.title('Histogram of Cluster 0')
plt.xlabel('Quality')
plt.ylabel('Frequency')
plt.show()

plt.hist([wine_0_3,wine_0_4,wine_0_5,wine_0_6,wine_0_7,wine_0_8], bins=6, density=True, stacked=True, color=['green', 'red', "yellow", "blue", "pink", "orange"], label = ['Quality=3', 'Quality=4','Quality=5','Quality=6','Quality=3','Quality=8' ])
handles, labels = plt.gca().get_legend_handles_labels()
plt.legend(reversed(handles), reversed(labels))
plt.title('Histogram of Cluster 0')
plt.xlabel('Quality')
plt.ylabel('Frequency')
plt.show()

plt.hist([wine_1_3,wine_1_4,wine_1_5,wine_1_6,wine_1_7,wine_1_8], bins=6, stacked=True, color=['green', 'red', "yellow", "blue", "pink", "orange"], label = ['Quality=3', 'Quality=4','Quality=5','Quality=6','Quality=3','Quality=8' ])
handles, labels = plt.gca().get_legend_handles_labels()
plt.legend(reversed(handles), reversed(labels))
plt.title('Histogram of Cluster 1')
plt.xlabel('Quality')
plt.ylabel('Frequency')
plt.show()

plt.hist([wine_1_3,wine_1_4,wine_1_5,wine_1_6,wine_1_7,wine_1_8], bins=6, density = True, stacked=True, color=['green', 'red', "yellow", "blue", "pink", "orange"], label = ['Quality=3', 'Quality=4','Quality=5','Quality=6','Quality=3','Quality=8' ])
handles, labels = plt.gca().get_legend_handles_labels()
plt.legend(reversed(handles), reversed(labels))
plt.title('Histogram of Cluster 1')
plt.xlabel('Quality')
plt.ylabel('Frequency')
plt.show()

plt.hist([wine_2_3,wine_2_4,wine_2_5,wine_2_6,wine_2_7,wine_2_8], bins=5, stacked=True, color=['green', 'red', "yellow", "blue", "pink", "orange"], label = ['Quality=3', 'Quality=4','Quality=5','Quality=6','Quality=3','Quality=8' ])
handles, labels = plt.gca().get_legend_handles_labels()
plt.legend(reversed(handles), reversed(labels))
plt.title('Histogram of Cluster 2')
plt.xlabel('Quality')
plt.ylabel('Frequency')
plt.show()

plt.hist([wine_2_3,wine_2_4,wine_2_5,wine_2_6,wine_2_7,wine_2_8], bins=5, density=True ,stacked=True, color=['green', 'red', "yellow", "blue", "pink", "orange"], label = ['Quality=3', 'Quality=4','Quality=5','Quality=6','Quality=3','Quality=8' ])
handles, labels = plt.gca().get_legend_handles_labels()
plt.legend(reversed(handles), reversed(labels))
plt.title('Histogram of Cluster 2')
plt.xlabel('Quality')
plt.ylabel('Frequency')
plt.show()